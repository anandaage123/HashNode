---
title: "Automating AWS Resource Tracking with Bash Scripts"
seoTitle: "Automating AWS Resource Tracking with Bash Scripts | Beginner-Friendly"
seoDescription: "Learn how to automate AWS resource reporting with Bash scripts and AWS CLI. Step-by-step guide with examples to list S3, EC2, Lambda, and IAM resources. Per"
datePublished: Mon Sep 01 2025 18:51:05 GMT+0000 (Coordinated Universal Time)
cuid: cmf1h6g6d000202ldd561cdj2
slug: automating-aws-resource-tracking-with-bash-scripts
cover: https://cdn.hashnode.com/res/hashnode/image/stock/unsplash/4Mw7nkQDByk/upload/3831ee8d1431594e3683061077a3cdb3.jpeg
tags: lambda, ec2, aws, cloud-computing, s3, iam, bash-scripting, aws-cli, cloud-automation, aws-for-beginners, devops-automation

---

Working with AWS often means switching between different services — S3, EC2, Lambda, IAM, and more. Manually checking all these resources can become time-consuming. Instead, you can automate resource reporting using simple Bash scripts. This blog will guide you through writing a Bash script to interact with AWS CLI and generate a consolidated resource usage report.

---

## Prerequisites

Before you begin, make sure you have:

1. **AWS CLI v2 installed** on your system. Install it using your system’s package manager:
    
    ```bash
    # macOS
    brew install awscli
    
    # Ubuntu/Debian
    sudo apt-get update && sudo apt-get install awscli -y
    
    # RHEL/CentOS
    sudo yum install awscli -y
    ```
    
    > Note: AWS CLI v2 is the recommended version. Avoid using `pip` because it installs the older v1 version.
    
2. **Configured AWS credentials** (Access Key and Secret Key) using:
    
    ```bash
    aws configure
    ```
    
    You’ll be prompted for:
    
    * AWS Access Key ID
        
    * AWS Secret Access Key
        
    * Default region (e.g., `us-east-1`)
        
    * Default output format (e.g., `json`)
        
3. **jq installed** for parsing JSON output:
    
    ```bash
    sudo apt-get install jq   # Linux
    brew install jq           # macOS
    ```
    

---

## The Bash Script

Here’s a working script to report AWS resource usage:

```bash
#!/bin/bash

#############
# Author: Anand Aage
# Date: 30 August
# Version: v1
# This script will report the AWS resource usage.
##########

set -x  # Debug mode: prints commands before execution
set -e  # Exit immediately if any command fails

OUTPUT_FILE="resource_tracker.txt"

# list S3 buckets
echo 'Print list of S3 buckets' > $OUTPUT_FILE
aws s3 ls >> $OUTPUT_FILE

# list EC2 instances
echo 'Print list of EC2 instances' >> $OUTPUT_FILE
aws ec2 describe-instances | jq -r '.Reservations[].Instances[].InstanceId' >> $OUTPUT_FILE

# list AWS Lambda functions
echo 'Print list of Lambda functions' >> $OUTPUT_FILE
aws lambda list-functions | jq -r '.Functions[].FunctionName' >> $OUTPUT_FILE

# list IAM Users
echo 'Print list of IAM users' >> $OUTPUT_FILE
aws iam list-users | jq -r '.Users[].UserName' >> $OUTPUT_FILE
```

---

## How It Works

1. **Debug and Exit Options**
    
    * `set -x`: Shows each command as it runs (helpful for debugging).
        
    * `set -e`: Stops execution if any command fails.
        
2. **Output File**  
    The script writes everything into `resource_tracker.txt`. The file gets overwritten when the script runs again, ensuring you always get fresh data.
    
3. **Resource Sections**
    
    * **S3 Buckets:** Lists all buckets in your account.
        
    * **EC2 Instances:** Extracts only instance IDs using `jq` for clarity.
        
    * **Lambda Functions:** Lists only function names instead of raw JSON.
        
    * **IAM Users:** Shows only usernames instead of entire JSON output.
        

---

## Example Output

Running the script generates a file like this:

```plaintext
Print list of S3 buckets
2025-08-22 16:47:18 anand-secound-via-cli
2025-08-22 16:43:31 first-anand

Print list of EC2 instances
i-0183d5dc783e5ebdd
i-0fedcba9876543210

Print list of Lambda functions
MyLambdaFunction
ProcessDataLambda

Print list of IAM users
Anand
```

---

## Why This Matters

* **Automation:** Saves time compared to manually checking each AWS service.
    
* **Audit-Friendly:** You can schedule this script with a cron job to track resources regularly.
    
* **Recruiter-Ready:** Demonstrates your ability to automate cloud tasks — a skill valued in DevOps and cloud engineering roles.
    

---

## Next Steps

* Extend the script to include other services like RDS, CloudFormation, or DynamoDB.
    
* Store reports in an S3 bucket for long-term tracking.
    
* Integrate with email or Slack to send automated daily reports.
    

---

### Final Thoughts

This script is a beginner-friendly way to combine Bash with AWS CLI. By automating routine tasks, you not only save time but also showcase practical cloud automation skills to recruiters and hiring managers. Start with this script, customize it, and expand your cloud automation toolkit.